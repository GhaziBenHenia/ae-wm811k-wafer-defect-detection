{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51feba32",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "742b2e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a5a340ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow: 2.11.1\n",
      "Device: CPU\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow:\", tf.__version__)\n",
    "print(\"Device:\", 'GPU' if tf.config.list_physical_devices('GPU') else 'CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c0e347",
   "metadata": {},
   "source": [
    "# -------------------- CONFIG --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e06a4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE        = 64\n",
    "BATCH_AE        = 512\n",
    "BATCH_CLF       = 512\n",
    "\n",
    "# AE pretrain\n",
    "EPOCHS_AE       = 10 #tested with 5, 10, 20\n",
    "\n",
    "# Classifier training (A: freeze then unfreeze)\n",
    "FREEZE_EPOCHS   = 10\n",
    "UNFREEZE_EPOCHS = 10\n",
    "LR_FREEZE       = 1e-3\n",
    "LR_UNFREEZE     = 5e-4\n",
    "\n",
    "# Classifier training (B: no freezing)\n",
    "EPOCHS_CLF_NOFREEZE = 10 #tested with 5, 10, 20\n",
    "LR_NOFREEZE         = 1e-3\n",
    "\n",
    "\n",
    "# Classifier training (C: frozen encoder)\n",
    "FREEZE_EPOCHS_C   = 50\n",
    "\n",
    "\n",
    "VAL_SPLIT       = 0.15\n",
    "SEED            = 42 #tested with 1, 42, 100 for reproducibility\n",
    "\n",
    "# Balancing targets (training only)\n",
    "MIN_DEFECT_TRAIN = 3000    # minimum per defect class in training\n",
    "MAX_NONE_TRAIN   = 20000   # maximum 'None' used for training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30bde1e",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2bd3cbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ROOT_PROC = Path('processed_images')\n",
    "ROOT_DIST = Path('processed_aux/dist')\n",
    "ROOT_BAD  = Path('processed_masks/bad')\n",
    "META_CSV  = Path('converted_images/metadata.csv')\n",
    "\n",
    "CLASSES  = ['Center','Donut','Edge-Loc','Edge-Ring','Loc','Random','Scratch','Near-Full','None']\n",
    "CLS2ID   = {c:i for i,c in enumerate(CLASSES)}\n",
    "N_CLASSES = len(CLASSES)\n",
    "DEFECT_CLASSES = [c for c in CLASSES if c != 'None']\n",
    "\n",
    "OUT_DIR = Path('ae_all_experiments')\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ENCODER_PATH = OUT_DIR / 'encoder.keras'\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "rng = np.random.default_rng(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c89b29d",
   "metadata": {},
   "source": [
    "# -------------------- Dataset (labeled only; 3-channel preprocessing) --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "180686a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canon_label(s):\n",
    "    if s is None: return 'Unlabeled'\n",
    "    s = str(s).strip().strip('_').replace('_','-').lower()\n",
    "    table = {\n",
    "        'center':'Center','donut':'Donut','edge-loc':'Edge-Loc','edge-ring':'Edge-Ring',\n",
    "        'loc':'Loc','random':'Random','scratch':'Scratch','near-full':'Near-Full',\n",
    "        'none':'None','unlabeled':'Unlabeled'\n",
    "    }\n",
    "    return table.get(s, 'Unlabeled')\n",
    "\n",
    "assert META_CSV.exists(), \"metadata.csv not found at converted_images/metadata.csv\"\n",
    "meta = pd.read_csv(META_CSV)\n",
    "for col in ['file','label','split']:\n",
    "    if col not in meta.columns:\n",
    "        raise ValueError(f\"metadata.csv missing required column: {col}\")\n",
    "meta['label'] = meta['label'].apply(canon_label)\n",
    "\n",
    "def triplet_paths(rel):\n",
    "    p = Path(rel)\n",
    "    return (ROOT_PROC/p, ROOT_DIST/p, ROOT_BAD/p)\n",
    "\n",
    "rows = []\n",
    "for _, r in meta.iterrows():\n",
    "    w, d, b = triplet_paths(r['file'])\n",
    "    rows.append([str(w), str(d), str(b), r['label'], r['split']])\n",
    "df = pd.DataFrame(rows, columns=['wafer','dist','bad','label','split'])\n",
    "\n",
    "mask = df['wafer'].apply(lambda p: Path(p).exists()) \\\n",
    "     & df['dist'].apply(lambda p: Path(p).exists()) \\\n",
    "     & df['bad'].apply(lambda p: Path(p).exists())\n",
    "df = df[mask].reset_index(drop=True)\n",
    "\n",
    "df_l = df[df['label'].isin(CLASSES)].reset_index(drop=True)  # labeled only\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8daa9",
   "metadata": {},
   "source": [
    "# Train/Test split (uses metadata if present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "174b8b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: No usable train/test in metadata. Creating a stratified 80/20 split.\n",
      "Train labeled: 138360 | Test labeled: 34590\n"
     ]
    }
   ],
   "source": [
    "train_df = df_l[df_l['split'].astype(str).str.lower().str.startswith('train')].reset_index(drop=True)\n",
    "test_df  = df_l[df_l['split'].astype(str).str.lower().str.startswith('test')].reset_index(drop=True)\n",
    "if len(train_df) == 0 or len(test_df) == 0:\n",
    "    print(\"INFO: No usable train/test in metadata. Creating a stratified 80/20 split.\")\n",
    "    train_df, test_df = train_test_split(df_l, test_size=0.2, random_state=SEED, stratify=df_l['label'])\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    test_df  = test_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Train labeled: {len(train_df)} | Test labeled: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9f8794",
   "metadata": {},
   "source": [
    "# -------------------- Balance TRAIN (upsample defects, downsample None) --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d75d52f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced TRAIN counts:\n",
      "label\n",
      "Center        3435\n",
      "Donut         3000\n",
      "Edge-Loc      4151\n",
      "Edge-Ring     7744\n",
      "Loc           3000\n",
      "Random        3000\n",
      "Scratch       3000\n",
      "Near-Full     3000\n",
      "None         20000\n",
      "Name: count, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "def balance_supervised_train(train_df,\n",
    "                             min_defect=MIN_DEFECT_TRAIN,\n",
    "                             max_none=MAX_NONE_TRAIN):\n",
    "    none_all = train_df[train_df['label'] == 'None'].reset_index(drop=True)\n",
    "    defects_all = train_df[train_df['label'] != 'None'].reset_index(drop=True)\n",
    "\n",
    "    # Downsample None to at most max_none\n",
    "    if len(none_all) > max_none:\n",
    "        none_bal = none_all.sample(max_none, random_state=SEED).reset_index(drop=True)\n",
    "    else:\n",
    "        none_bal = none_all\n",
    "\n",
    "    # Upsample each defect to at least min_defect\n",
    "    blocks = []\n",
    "    for c in DEFECT_CLASSES:\n",
    "        sub = defects_all[defects_all['label'] == c].reset_index(drop=True)\n",
    "        if len(sub) == 0:\n",
    "            continue\n",
    "        if len(sub) < min_defect:\n",
    "            need = min_defect - len(sub)\n",
    "            supl = sub.sample(need, replace=True, random_state=SEED)\n",
    "            sub_bal = pd.concat([sub, supl], axis=0).reset_index(drop=True)\n",
    "        else:\n",
    "            sub_bal = sub\n",
    "        blocks.append(sub_bal)\n",
    "\n",
    "    defects_bal = pd.concat(blocks, axis=0).reset_index(drop=True)\n",
    "    train_bal = pd.concat([defects_bal, none_bal], axis=0).sample(frac=1.0, random_state=SEED).reset_index(drop=True)\n",
    "    return train_bal\n",
    "\n",
    "train_df_bal = balance_supervised_train(train_df)\n",
    "print(\"\\nBalanced TRAIN counts:\")\n",
    "print(train_df_bal['label'].value_counts().reindex(CLASSES).fillna(0).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c1a97f",
   "metadata": {},
   "source": [
    "# -------------------- Preprocess & tf.data --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cd537979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gray64(path):\n",
    "    img = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(path)\n",
    "    if img.shape[0] != IMG_SIZE or img.shape[1] != IMG_SIZE:\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE), interpolation=cv2.INTER_NEAREST)\n",
    "    return img\n",
    "\n",
    "def load_triplet_row(row):\n",
    "    w = read_gray64(row['wafer'])\n",
    "    d = read_gray64(row['dist'])\n",
    "    b = read_gray64(row['bad'])\n",
    "    # wafer: {0,127,255} -> {0,0.5,1}\n",
    "    w = (w // 127).astype(np.float32) / 2.0\n",
    "    d = (d.astype(np.float32) / 255.0)\n",
    "    b = (b.astype(np.float32) / 255.0)\n",
    "    x = np.stack([w, d, b], axis=-1).astype(np.float32)  # H,W,3\n",
    "    return x\n",
    "\n",
    "def gen_x(frame):\n",
    "    for _, r in frame.iterrows():\n",
    "        yield load_triplet_row(r)\n",
    "\n",
    "def gen_xy(frame):\n",
    "    for _, r in frame.iterrows():\n",
    "        yield load_triplet_row(r), CLS2ID[r['label']]\n",
    "\n",
    "def make_ds_ae(frame, batch, shuffle=True):\n",
    "    ds_x = tf.data.Dataset.from_generator(\n",
    "        lambda: gen_x(frame),\n",
    "        output_signature=tf.TensorSpec(shape=(IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32)\n",
    "    )\n",
    "    if shuffle:\n",
    "        ds_x = ds_x.shuffle(4096, seed=SEED)\n",
    "    ds = ds_x.map(lambda x: (x, x), num_parallel_calls=AUTOTUNE)\n",
    "    ds = ds.batch(batch).prefetch(AUTOTUNE)\n",
    "    return ds\n",
    "\n",
    "def make_ds_xy(frame, batch, shuffle=True):\n",
    "    ds = tf.data.Dataset.from_generator(\n",
    "        lambda: gen_xy(frame),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(IMG_SIZE, IMG_SIZE, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.int32),\n",
    "        )\n",
    "    )\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(4096, seed=SEED)\n",
    "    ds = ds.batch(batch).prefetch(AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bd0ce550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Balanced splits ( Train: 42780 | Val: 7550)\n"
     ]
    }
   ],
   "source": [
    "train_bal, val_bal = train_test_split(\n",
    "    train_df_bal, test_size=VAL_SPLIT, random_state=SEED, stratify=train_df_bal['label']\n",
    ")\n",
    "train_bal = train_bal.reset_index(drop=True)\n",
    "val_bal   = val_bal.reset_index(drop=True)\n",
    "print(f\"\\nBalanced splits ( Train: {len(train_bal)} | Val: {len(val_bal)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9498c57e",
   "metadata": {},
   "source": [
    "# Build datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "25fd3a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_train_ds = make_ds_ae(train_bal, BATCH_AE, shuffle=True)\n",
    "ae_val_ds   = make_ds_ae(val_bal,   BATCH_AE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "41784d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_train_ds = make_ds_xy(train_bal, BATCH_CLF, shuffle=True)\n",
    "clf_val_ds   = make_ds_xy(val_bal,   BATCH_CLF, shuffle=False)\n",
    "test_ds      = make_ds_xy(test_df,   BATCH_CLF, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d2a17e",
   "metadata": {},
   "source": [
    "# -------------------- Autoencoder --------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c68862d",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "fb7e825f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, filters, name_prefix):\n",
    "    x = layers.Conv2D(filters, 3, padding='same', use_bias=False, name=f'{name_prefix}_conv')(x)\n",
    "    x = layers.BatchNormalization(name=f'{name_prefix}_bn')(x)\n",
    "    x = layers.ReLU(name=f'{name_prefix}_relu')(x)\n",
    "    return x\n",
    "\n",
    "def build_autoencoder_big():\n",
    "    inp = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='input')\n",
    "    # Encoder \n",
    "    x = conv_block(inp, 64,  'enc1_1')\n",
    "    x = conv_block(x,  64,  'enc1_2')\n",
    "    x = layers.MaxPooling2D(name='enc1_pool')(x)           # 32x32\n",
    "\n",
    "    x = conv_block(x,  128, 'enc2_1')\n",
    "    x = conv_block(x,  128, 'enc2_2')\n",
    "    x = layers.MaxPooling2D(name='enc2_pool')(x)           # 16x16\n",
    "\n",
    "    x = conv_block(x,  128, 'enc3_1')\n",
    "    x = conv_block(x,  128, 'enc3_2')\n",
    "    latent = layers.MaxPooling2D(name='latent')(x)         # 8x8 (bottleneck)\n",
    "\n",
    "    # Decoder\n",
    "    y = conv_block(latent, 128, 'dec1_pre')\n",
    "    y = layers.Conv2DTranspose(128, 3, strides=2, padding='same', use_bias=False, name='dec1_deconv')(y)  # 16x16\n",
    "    y = layers.BatchNormalization(name='dec1_bn')(y)\n",
    "    y = layers.ReLU(name='dec1_relu')(y)\n",
    "\n",
    "    y = conv_block(y, 64, 'dec2_pre')\n",
    "    y = layers.Conv2DTranspose(64, 3, strides=2, padding='same', use_bias=False, name='dec2_deconv')(y)   # 32x32\n",
    "    y = layers.BatchNormalization(name='dec2_bn')(y)\n",
    "    y = layers.ReLU(name='dec2_relu')(y)\n",
    "\n",
    "    y = layers.Conv2DTranspose(32, 3, strides=2, padding='same', use_bias=False, name='dec3_deconv')(y)   # 64x64\n",
    "    y = layers.BatchNormalization(name='dec3_bn')(y)\n",
    "    y = layers.ReLU(name='dec3_relu')(y)\n",
    "\n",
    "    recon = layers.Conv2D(3, 3, padding='same', activation='sigmoid', name='recon')(y)\n",
    "    ae = models.Model(inp, recon, name='autoencoder_big')\n",
    "    ae.compile(optimizer=optimizers.Adam(1e-3), loss='mse')\n",
    "    return ae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392aa6d0",
   "metadata": {},
   "source": [
    "# === AE training & encoder saving ==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a00201c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder_big\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input (InputLayer)          [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " enc1_1_conv (Conv2D)        (None, 64, 64, 64)        1728      \n",
      "                                                                 \n",
      " enc1_1_bn (BatchNormalizati  (None, 64, 64, 64)       256       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " enc1_1_relu (ReLU)          (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " enc1_2_conv (Conv2D)        (None, 64, 64, 64)        36864     \n",
      "                                                                 \n",
      " enc1_2_bn (BatchNormalizati  (None, 64, 64, 64)       256       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " enc1_2_relu (ReLU)          (None, 64, 64, 64)        0         \n",
      "                                                                 \n",
      " enc1_pool (MaxPooling2D)    (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " enc2_1_conv (Conv2D)        (None, 32, 32, 128)       73728     \n",
      "                                                                 \n",
      " enc2_1_bn (BatchNormalizati  (None, 32, 32, 128)      512       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " enc2_1_relu (ReLU)          (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " enc2_2_conv (Conv2D)        (None, 32, 32, 128)       147456    \n",
      "                                                                 \n",
      " enc2_2_bn (BatchNormalizati  (None, 32, 32, 128)      512       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " enc2_2_relu (ReLU)          (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " enc2_pool (MaxPooling2D)    (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " enc3_1_conv (Conv2D)        (None, 16, 16, 128)       147456    \n",
      "                                                                 \n",
      " enc3_1_bn (BatchNormalizati  (None, 16, 16, 128)      512       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " enc3_1_relu (ReLU)          (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " enc3_2_conv (Conv2D)        (None, 16, 16, 128)       147456    \n",
      "                                                                 \n",
      " enc3_2_bn (BatchNormalizati  (None, 16, 16, 128)      512       \n",
      " on)                                                             \n",
      "                                                                 \n",
      " enc3_2_relu (ReLU)          (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " latent (MaxPooling2D)       (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " dec1_pre_conv (Conv2D)      (None, 8, 8, 128)         147456    \n",
      "                                                                 \n",
      " dec1_pre_bn (BatchNormaliza  (None, 8, 8, 128)        512       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dec1_pre_relu (ReLU)        (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " dec1_deconv (Conv2DTranspos  (None, 16, 16, 128)      147456    \n",
      " e)                                                              \n",
      "                                                                 \n",
      " dec1_bn (BatchNormalization  (None, 16, 16, 128)      512       \n",
      " )                                                               \n",
      "                                                                 \n",
      " dec1_relu (ReLU)            (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " dec2_pre_conv (Conv2D)      (None, 16, 16, 64)        73728     \n",
      "                                                                 \n",
      " dec2_pre_bn (BatchNormaliza  (None, 16, 16, 64)       256       \n",
      " tion)                                                           \n",
      "                                                                 \n",
      " dec2_pre_relu (ReLU)        (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " dec2_deconv (Conv2DTranspos  (None, 32, 32, 64)       36864     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " dec2_bn (BatchNormalization  (None, 32, 32, 64)       256       \n",
      " )                                                               \n",
      "                                                                 \n",
      " dec2_relu (ReLU)            (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " dec3_deconv (Conv2DTranspos  (None, 64, 64, 32)       18432     \n",
      " e)                                                              \n",
      "                                                                 \n",
      " dec3_bn (BatchNormalization  (None, 64, 64, 32)       128       \n",
      " )                                                               \n",
      "                                                                 \n",
      " dec3_relu (ReLU)            (None, 64, 64, 32)        0         \n",
      "                                                                 \n",
      " recon (Conv2D)              (None, 64, 64, 3)         867       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 983,715\n",
      "Trainable params: 981,603\n",
      "Non-trainable params: 2,112\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ae = build_autoencoder_big()\n",
    "ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fd811cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "84/84 [==============================] - 2027s 23s/step - loss: 0.0241 - val_loss: 0.0573\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 1648s 19s/step - loss: 0.0090 - val_loss: 0.0502\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 1253s 14s/step - loss: 0.0075 - val_loss: 0.0379\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 2012s 23s/step - loss: 0.0069 - val_loss: 0.0257\n",
      "Epoch 5/10\n",
      "84/84 [==============================] - 1872s 22s/step - loss: 0.0063 - val_loss: 0.0167\n",
      "Epoch 6/10\n",
      "84/84 [==============================] - 1713s 20s/step - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 7/10\n",
      "84/84 [==============================] - 1776s 21s/step - loss: 0.0055 - val_loss: 0.0063\n",
      "Epoch 8/10\n",
      "84/84 [==============================] - 1459s 17s/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 9/10\n",
      "84/84 [==============================] - 1800s 21s/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 10/10\n",
      "84/84 [==============================] - 1906s 22s/step - loss: 0.0044 - val_loss: 0.0049\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Saved encoder: ae_all_experiments\\encoder.keras\n"
     ]
    }
   ],
   "source": [
    "ae.fit(\n",
    "    ae_train_ds,\n",
    "    validation_data=ae_val_ds,\n",
    "    epochs=EPOCHS_AE,\n",
    "    verbose=1,\n",
    "    callbacks=[callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)]\n",
    ")\n",
    "encoder = models.Model(ae.input, ae.get_layer('latent').output, name='encoder')\n",
    "encoder.save(ENCODER_PATH)\n",
    "print(\"Saved encoder:\", ENCODER_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b622d34",
   "metadata": {},
   "source": [
    "# -------------------- Classifier head builder --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ed89dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier_from_encoder(encoder_model, dense_units=256, dropout=0.25):\n",
    "    clf_in = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='input')\n",
    "    feat   = encoder_model(clf_in)\n",
    "    gap    = layers.GlobalAveragePooling2D(name='gap')(feat)\n",
    "    h      = layers.Dense(dense_units, activation='relu', name='head_dense')(gap)\n",
    "    h      = layers.Dropout(dropout, name='head_drop')(h)\n",
    "    logits = layers.Dense(N_CLASSES, activation=None, name='logits')(h)\n",
    "    prob   = layers.Softmax(name='softmax')(logits)\n",
    "    clf    = models.Model(clf_in, prob, name='classifier_big')\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b208dd8c",
   "metadata": {},
   "source": [
    "# -------------------- Utility: Evaluate on ORIGINAL test split --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "76b77509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_and_print(model, test_ds, tag):\n",
    "    y_true, y_pred = [], []\n",
    "    for xb, yb in test_ds:\n",
    "        p = model.predict(xb, verbose=0)\n",
    "        y_true += yb.numpy().tolist()\n",
    "        y_pred += p.argmax(axis=1).tolist()\n",
    "    overall_acc = accuracy_score(y_true, y_pred)\n",
    "    macro_f1    = f1_score(y_true, y_pred, average='macro')\n",
    "    print(f\"\\n=== Test Results ({tag}) ===\")\n",
    "    print(\"Overall accuracy:\", f\"{overall_acc:.4f}\")\n",
    "    print(\"Macro-F1        :\", f\"{macro_f1:.4f}\")\n",
    "    print(classification_report(y_true, y_pred, target_names=CLASSES, zero_division=0))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00108fd3",
   "metadata": {},
   "source": [
    "# -------------------- EXPERIMENT A — Freeze then Unfreeze --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a3950a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ EXPERIMENT A: Freeze_Unfreeze ================\n",
      "Epoch 1/10\n",
      "84/84 [==============================] - 232s 2s/step - loss: 1.5999 - accuracy: 0.4679 - val_loss: 1.4167 - val_accuracy: 0.5230\n",
      "Epoch 2/10\n",
      "84/84 [==============================] - 216s 3s/step - loss: 1.3538 - accuracy: 0.5395 - val_loss: 1.2746 - val_accuracy: 0.5502\n",
      "Epoch 3/10\n",
      "84/84 [==============================] - 21909s 264s/step - loss: 1.2549 - accuracy: 0.5741 - val_loss: 1.2073 - val_accuracy: 0.5887\n",
      "Epoch 4/10\n",
      "84/84 [==============================] - 165s 2s/step - loss: 1.1955 - accuracy: 0.6045 - val_loss: 1.1481 - val_accuracy: 0.6184\n",
      "Epoch 5/10\n",
      "83/84 [============================>.] - ETA: 1s - loss: 1.1505 - accuracy: 0.6282"
     ]
    }
   ],
   "source": [
    "print(\"\\n================ EXPERIMENT A: Freeze_Unfreeze ================\")\n",
    "enc_A = tf.keras.models.load_model(ENCODER_PATH, compile=False)\n",
    "for layer in enc_A.layers:\n",
    "    layer.trainable = False\n",
    "clf_A = build_classifier_from_encoder(enc_A, dense_units=384, dropout=0.3)\n",
    "clf_A.compile(optimizer=optimizers.Adam(LR_FREEZE),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "clf_A.fit(clf_train_ds, validation_data=clf_val_ds, epochs=FREEZE_EPOCHS, verbose=1)\n",
    "for layer in enc_A.layers:\n",
    "    layer.trainable = True\n",
    "clf_A.compile(optimizer=optimizers.Adam(LR_UNFREEZE),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "clf_A.fit(clf_train_ds, validation_data=clf_val_ds, epochs=UNFREEZE_EPOCHS, verbose=1,\n",
    "          callbacks=[callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)])\n",
    "eval_and_print(clf_A, test_ds, tag=\"A: Freeze_Unfreeze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edd96d2",
   "metadata": {},
   "source": [
    "# -------------------- EXPERIMENT B — No Freezing (fresh encoder) --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1978fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n================ EXPERIMENT B: No Freezing ================\")\n",
    "enc_B = tf.keras.models.load_model(ENCODER_PATH, compile=False)  # reuse saved encoder\n",
    "for layer in enc_B.layers:\n",
    "    layer.trainable = True\n",
    "clf_B = build_classifier_from_encoder(enc_B, dense_units=384, dropout=0.3)\n",
    "clf_B.compile(optimizer=optimizers.Adam(LR_NOFREEZE),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "clf_B.fit(clf_train_ds, validation_data=clf_val_ds, epochs=EPOCHS_CLF_NOFREEZE, verbose=1,\n",
    "          callbacks=[callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)])\n",
    "\n",
    "eval_and_print(clf_B, test_ds, tag=\"B: No Freezing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6511da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier3_from_encoder(encoder_model, dense_units=256, dropout=0.25):\n",
    "    clf_in = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='input')\n",
    "    feat   = encoder_model(clf_in)\n",
    "    gap    = layers.GlobalAveragePooling2D(name='gap')(feat)\n",
    "    \n",
    "    h      = layers.Dense(dense_units, activation='relu', name='head_dense_1')(gap)\n",
    "    \n",
    "    h      = layers.Dense(dense_units // 2, activation='relu', name='head_dense_2')(h)\n",
    "    \n",
    "    h      = layers.Dropout(dropout, name='head_drop')(h)\n",
    "    \n",
    "    logits = layers.Dense(N_CLASSES, activation=None, name='logits')(h)\n",
    "    prob   = layers.Softmax(name='softmax')(logits)\n",
    "    \n",
    "    clf    = models.Model(clf_in, prob, name='classifier_bigger')\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab28a634",
   "metadata": {},
   "source": [
    "# -------------------- EXPERIMENT C: Freezen Encoder --------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cb3d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ EXPERIMENT A: Freeze → Unfreeze ================\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 1063s 12s/step - loss: 1.4788 - accuracy: 0.5103 - val_loss: 1.2637 - val_accuracy: 0.5694\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 138s 1s/step - loss: 1.2432 - accuracy: 0.5842 - val_loss: 1.1565 - val_accuracy: 0.6127\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 135s 2s/step - loss: 1.1431 - accuracy: 0.6270 - val_loss: 1.0619 - val_accuracy: 0.6511\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 144s 2s/step - loss: 1.0698 - accuracy: 0.6558 - val_loss: 0.9912 - val_accuracy: 0.6804\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 145s 2s/step - loss: 0.9920 - accuracy: 0.6852 - val_loss: 0.9183 - val_accuracy: 0.7205\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 142s 2s/step - loss: 0.9553 - accuracy: 0.6964 - val_loss: 0.9157 - val_accuracy: 0.7233\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 144s 2s/step - loss: 0.9056 - accuracy: 0.7139 - val_loss: 0.8578 - val_accuracy: 0.7321\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 140s 2s/step - loss: 0.8834 - accuracy: 0.7199 - val_loss: 0.8194 - val_accuracy: 0.7474\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 142s 2s/step - loss: 0.8507 - accuracy: 0.7295 - val_loss: 0.9165 - val_accuracy: 0.6918\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 140s 2s/step - loss: 0.8414 - accuracy: 0.7330 - val_loss: 0.7811 - val_accuracy: 0.7527\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 184s 2s/step - loss: 0.8076 - accuracy: 0.7432 - val_loss: 0.8127 - val_accuracy: 0.7368\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 188s 2s/step - loss: 0.8030 - accuracy: 0.7442 - val_loss: 0.7526 - val_accuracy: 0.7629\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 300s 4s/step - loss: 0.8005 - accuracy: 0.7454 - val_loss: 0.7409 - val_accuracy: 0.7656\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 528s 6s/step - loss: 0.7747 - accuracy: 0.7544 - val_loss: 0.7519 - val_accuracy: 0.7743\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 203s 2s/step - loss: 0.7571 - accuracy: 0.7597 - val_loss: 0.7628 - val_accuracy: 0.7544\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 221s 3s/step - loss: 0.7581 - accuracy: 0.7595 - val_loss: 0.7047 - val_accuracy: 0.7793\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 230s 3s/step - loss: 0.7375 - accuracy: 0.7683 - val_loss: 0.6983 - val_accuracy: 0.7722\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 165s 2s/step - loss: 0.7324 - accuracy: 0.7680 - val_loss: 0.6994 - val_accuracy: 0.7770\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 204s 2s/step - loss: 0.7383 - accuracy: 0.7651 - val_loss: 0.6983 - val_accuracy: 0.7774\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 221s 3s/step - loss: 0.7159 - accuracy: 0.7729 - val_loss: 0.7084 - val_accuracy: 0.7721\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 479s 6s/step - loss: 0.6967 - accuracy: 0.7775 - val_loss: 0.6653 - val_accuracy: 0.7878\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 424s 5s/step - loss: 0.7024 - accuracy: 0.7764 - val_loss: 0.7134 - val_accuracy: 0.7759\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 200s 2s/step - loss: 0.7026 - accuracy: 0.7780 - val_loss: 0.6849 - val_accuracy: 0.7770\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 189s 2s/step - loss: 0.6753 - accuracy: 0.7860 - val_loss: 0.6497 - val_accuracy: 0.7960\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 195s 2s/step - loss: 0.6847 - accuracy: 0.7818 - val_loss: 0.6471 - val_accuracy: 0.7917\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 191s 2s/step - loss: 0.6746 - accuracy: 0.7849 - val_loss: 0.6481 - val_accuracy: 0.7932\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 190s 2s/step - loss: 0.6797 - accuracy: 0.7836 - val_loss: 0.6789 - val_accuracy: 0.7801\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 188s 2s/step - loss: 0.6668 - accuracy: 0.7866 - val_loss: 0.6389 - val_accuracy: 0.7959\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 193s 2s/step - loss: 0.6616 - accuracy: 0.7885 - val_loss: 0.6980 - val_accuracy: 0.7807\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 196s 2s/step - loss: 0.6578 - accuracy: 0.7903 - val_loss: 0.6588 - val_accuracy: 0.7869\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 188s 2s/step - loss: 0.6757 - accuracy: 0.7843 - val_loss: 0.6529 - val_accuracy: 0.7879\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 199s 2s/step - loss: 0.6444 - accuracy: 0.7929 - val_loss: 0.6331 - val_accuracy: 0.7909\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 189s 2s/step - loss: 0.6502 - accuracy: 0.7910 - val_loss: 0.6565 - val_accuracy: 0.7938\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 184s 2s/step - loss: 0.6369 - accuracy: 0.7964 - val_loss: 0.6176 - val_accuracy: 0.8062\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 203s 2s/step - loss: 0.6355 - accuracy: 0.7962 - val_loss: 0.6049 - val_accuracy: 0.8023\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 198s 2s/step - loss: 0.6512 - accuracy: 0.7907 - val_loss: 0.6334 - val_accuracy: 0.7927\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 194s 2s/step - loss: 0.6369 - accuracy: 0.7954 - val_loss: 0.6044 - val_accuracy: 0.8068\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 193s 2s/step - loss: 0.6243 - accuracy: 0.7990 - val_loss: 0.6232 - val_accuracy: 0.7918\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 195s 2s/step - loss: 0.6212 - accuracy: 0.7986 - val_loss: 0.5996 - val_accuracy: 0.8046\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 194s 2s/step - loss: 0.6122 - accuracy: 0.8037 - val_loss: 0.6033 - val_accuracy: 0.8083\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 215s 3s/step - loss: 0.6200 - accuracy: 0.8014 - val_loss: 0.5810 - val_accuracy: 0.8074\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 214s 3s/step - loss: 0.6078 - accuracy: 0.8047 - val_loss: 0.5995 - val_accuracy: 0.8086\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 212s 2s/step - loss: 0.6094 - accuracy: 0.8030 - val_loss: 0.5854 - val_accuracy: 0.8091\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 529s 6s/step - loss: 0.6145 - accuracy: 0.8027 - val_loss: 0.6105 - val_accuracy: 0.8062\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 229s 2s/step - loss: 0.6028 - accuracy: 0.8062 - val_loss: 0.5850 - val_accuracy: 0.8106\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 202s 2s/step - loss: 0.6028 - accuracy: 0.8048 - val_loss: 0.6045 - val_accuracy: 0.8037\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 204s 2s/step - loss: 0.6125 - accuracy: 0.8019 - val_loss: 0.6333 - val_accuracy: 0.7952\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 205s 2s/step - loss: 0.6057 - accuracy: 0.8054 - val_loss: 0.5862 - val_accuracy: 0.8086\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 203s 2s/step - loss: 0.6033 - accuracy: 0.8055 - val_loss: 0.5970 - val_accuracy: 0.8135\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 202s 2s/step - loss: 0.5994 - accuracy: 0.8063 - val_loss: 0.5809 - val_accuracy: 0.8109\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f09e8cbe0>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n================ EXPERIMENT C: Freezen Encoder ================\")\n",
    "enc_A = tf.keras.models.load_model(ENCODER_PATH, compile=False)\n",
    "for layer in enc_A.layers:\n",
    "    layer.trainable = False\n",
    "clf_A = build_classifier3_from_encoder(enc_A, dense_units=384, dropout=0.3)\n",
    "clf_A.compile(optimizer=optimizers.Adam(LR_FREEZE),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "clf_A.fit(clf_train_ds, validation_data=clf_val_ds, epochs=FREEZE_EPOCHS_C, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "073a4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier3_no_encoder(dense_units=256, dropout=0.25):\n",
    "    clf_in = tf.keras.Input(shape=(IMG_SIZE, IMG_SIZE, 3), name='input')\n",
    "    gap    = tf.keras.layers.GlobalAveragePooling2D(name='gap')(clf_in)\n",
    "    h      = tf.keras.layers.Dense(dense_units, activation='relu', name='head_dense_1')(gap)\n",
    "    h      = tf.keras.layers.Dense(dense_units // 2, activation='relu', name='head_dense_2')(h)\n",
    "    h      = tf.keras.layers.Dropout(dropout, name='head_drop')(h)\n",
    "    logits = tf.keras.layers.Dense(N_CLASSES, activation=None, name='logits')(h)\n",
    "    prob   = tf.keras.layers.Softmax(name='softmax')(logits)\n",
    "    return tf.keras.Model(clf_in, prob, name='classifier_head_only')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a83c3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ EXPERIMENT A: No-Encoder =================\n",
      "Epoch 1/50\n",
      "84/84 [==============================] - 634s 7s/step - loss: 1.7580 - accuracy: 0.4370 - val_loss: 1.6138 - val_accuracy: 0.4583\n",
      "Epoch 2/50\n",
      "84/84 [==============================] - 98s 924ms/step - loss: 1.5587 - accuracy: 0.4740 - val_loss: 1.4668 - val_accuracy: 0.4968\n",
      "Epoch 3/50\n",
      "84/84 [==============================] - 43s 478ms/step - loss: 1.4417 - accuracy: 0.5063 - val_loss: 1.3831 - val_accuracy: 0.5212\n",
      "Epoch 4/50\n",
      "84/84 [==============================] - 43s 473ms/step - loss: 1.3793 - accuracy: 0.5283 - val_loss: 1.3334 - val_accuracy: 0.5372\n",
      "Epoch 5/50\n",
      "84/84 [==============================] - 42s 468ms/step - loss: 1.3394 - accuracy: 0.5418 - val_loss: 1.2999 - val_accuracy: 0.5483\n",
      "Epoch 6/50\n",
      "84/84 [==============================] - 46s 500ms/step - loss: 1.3103 - accuracy: 0.5568 - val_loss: 1.2763 - val_accuracy: 0.5603\n",
      "Epoch 7/50\n",
      "84/84 [==============================] - 42s 465ms/step - loss: 1.2894 - accuracy: 0.5693 - val_loss: 1.2550 - val_accuracy: 0.5870\n",
      "Epoch 8/50\n",
      "84/84 [==============================] - 42s 465ms/step - loss: 1.2732 - accuracy: 0.5772 - val_loss: 1.2552 - val_accuracy: 0.6098\n",
      "Epoch 9/50\n",
      "84/84 [==============================] - 210s 2s/step - loss: 1.2624 - accuracy: 0.5855 - val_loss: 1.2306 - val_accuracy: 0.5841\n",
      "Epoch 10/50\n",
      "84/84 [==============================] - 316s 3s/step - loss: 1.2487 - accuracy: 0.5924 - val_loss: 1.2276 - val_accuracy: 0.6163\n",
      "Epoch 11/50\n",
      "84/84 [==============================] - 35s 384ms/step - loss: 1.2408 - accuracy: 0.5968 - val_loss: 1.2084 - val_accuracy: 0.6085\n",
      "Epoch 12/50\n",
      "84/84 [==============================] - 35s 384ms/step - loss: 1.2296 - accuracy: 0.6018 - val_loss: 1.2041 - val_accuracy: 0.6054\n",
      "Epoch 13/50\n",
      "84/84 [==============================] - 35s 389ms/step - loss: 1.2210 - accuracy: 0.6067 - val_loss: 1.2101 - val_accuracy: 0.6057\n",
      "Epoch 14/50\n",
      "84/84 [==============================] - 35s 382ms/step - loss: 1.2197 - accuracy: 0.6075 - val_loss: 1.1925 - val_accuracy: 0.6143\n",
      "Epoch 15/50\n",
      "84/84 [==============================] - 35s 389ms/step - loss: 1.2160 - accuracy: 0.6092 - val_loss: 1.1899 - val_accuracy: 0.6250\n",
      "Epoch 16/50\n",
      "84/84 [==============================] - 35s 387ms/step - loss: 1.2119 - accuracy: 0.6121 - val_loss: 1.1846 - val_accuracy: 0.6211\n",
      "Epoch 17/50\n",
      "84/84 [==============================] - 38s 422ms/step - loss: 1.2095 - accuracy: 0.6127 - val_loss: 1.1800 - val_accuracy: 0.6273\n",
      "Epoch 18/50\n",
      "84/84 [==============================] - 37s 415ms/step - loss: 1.2049 - accuracy: 0.6156 - val_loss: 1.1781 - val_accuracy: 0.6311\n",
      "Epoch 19/50\n",
      "84/84 [==============================] - 38s 421ms/step - loss: 1.2012 - accuracy: 0.6169 - val_loss: 1.1740 - val_accuracy: 0.6264\n",
      "Epoch 20/50\n",
      "84/84 [==============================] - 36s 390ms/step - loss: 1.1991 - accuracy: 0.6183 - val_loss: 1.1713 - val_accuracy: 0.6289\n",
      "Epoch 21/50\n",
      "84/84 [==============================] - 38s 423ms/step - loss: 1.1951 - accuracy: 0.6199 - val_loss: 1.1689 - val_accuracy: 0.6286\n",
      "Epoch 22/50\n",
      "84/84 [==============================] - 35s 379ms/step - loss: 1.1932 - accuracy: 0.6201 - val_loss: 1.1716 - val_accuracy: 0.6254\n",
      "Epoch 23/50\n",
      "84/84 [==============================] - 36s 395ms/step - loss: 1.1948 - accuracy: 0.6196 - val_loss: 1.1638 - val_accuracy: 0.6334\n",
      "Epoch 24/50\n",
      "84/84 [==============================] - 35s 387ms/step - loss: 1.1897 - accuracy: 0.6219 - val_loss: 1.1660 - val_accuracy: 0.6391\n",
      "Epoch 25/50\n",
      "84/84 [==============================] - 36s 404ms/step - loss: 1.1875 - accuracy: 0.6222 - val_loss: 1.1635 - val_accuracy: 0.6294\n",
      "Epoch 26/50\n",
      "84/84 [==============================] - 38s 417ms/step - loss: 1.1892 - accuracy: 0.6224 - val_loss: 1.1571 - val_accuracy: 0.6340\n",
      "Epoch 27/50\n",
      "84/84 [==============================] - 41s 456ms/step - loss: 1.1820 - accuracy: 0.6248 - val_loss: 1.1607 - val_accuracy: 0.6338\n",
      "Epoch 28/50\n",
      "84/84 [==============================] - 46s 509ms/step - loss: 1.1819 - accuracy: 0.6252 - val_loss: 1.1590 - val_accuracy: 0.6310\n",
      "Epoch 29/50\n",
      "84/84 [==============================] - 52s 580ms/step - loss: 1.1808 - accuracy: 0.6263 - val_loss: 1.1637 - val_accuracy: 0.6442\n",
      "Epoch 30/50\n",
      "84/84 [==============================] - 52s 569ms/step - loss: 1.1831 - accuracy: 0.6236 - val_loss: 1.1585 - val_accuracy: 0.6313\n",
      "Epoch 31/50\n",
      "84/84 [==============================] - 44s 479ms/step - loss: 1.1793 - accuracy: 0.6252 - val_loss: 1.1511 - val_accuracy: 0.6396\n",
      "Epoch 32/50\n",
      "84/84 [==============================] - 60s 682ms/step - loss: 1.1775 - accuracy: 0.6258 - val_loss: 1.1483 - val_accuracy: 0.6344\n",
      "Epoch 33/50\n",
      "84/84 [==============================] - 116s 1s/step - loss: 1.1751 - accuracy: 0.6273 - val_loss: 1.1488 - val_accuracy: 0.6332\n",
      "Epoch 34/50\n",
      "84/84 [==============================] - 114s 1s/step - loss: 1.1739 - accuracy: 0.6277 - val_loss: 1.1478 - val_accuracy: 0.6449\n",
      "Epoch 35/50\n",
      "84/84 [==============================] - 133s 1s/step - loss: 1.1726 - accuracy: 0.6281 - val_loss: 1.1451 - val_accuracy: 0.6436\n",
      "Epoch 36/50\n",
      "84/84 [==============================] - 66s 656ms/step - loss: 1.1729 - accuracy: 0.6260 - val_loss: 1.1611 - val_accuracy: 0.6229\n",
      "Epoch 37/50\n",
      "84/84 [==============================] - 43s 474ms/step - loss: 1.1722 - accuracy: 0.6271 - val_loss: 1.1426 - val_accuracy: 0.6351\n",
      "Epoch 38/50\n",
      "84/84 [==============================] - 42s 461ms/step - loss: 1.1679 - accuracy: 0.6284 - val_loss: 1.1448 - val_accuracy: 0.6375\n",
      "Epoch 39/50\n",
      "84/84 [==============================] - 43s 476ms/step - loss: 1.1682 - accuracy: 0.6284 - val_loss: 1.1396 - val_accuracy: 0.6381\n",
      "Epoch 40/50\n",
      "84/84 [==============================] - 43s 477ms/step - loss: 1.1680 - accuracy: 0.6273 - val_loss: 1.1449 - val_accuracy: 0.6344\n",
      "Epoch 41/50\n",
      "84/84 [==============================] - 43s 472ms/step - loss: 1.1643 - accuracy: 0.6296 - val_loss: 1.1394 - val_accuracy: 0.6450\n",
      "Epoch 42/50\n",
      "84/84 [==============================] - 43s 477ms/step - loss: 1.1623 - accuracy: 0.6303 - val_loss: 1.1353 - val_accuracy: 0.6430\n",
      "Epoch 43/50\n",
      "84/84 [==============================] - 43s 477ms/step - loss: 1.1633 - accuracy: 0.6292 - val_loss: 1.1453 - val_accuracy: 0.6313\n",
      "Epoch 44/50\n",
      "84/84 [==============================] - 42s 469ms/step - loss: 1.1640 - accuracy: 0.6294 - val_loss: 1.1346 - val_accuracy: 0.6426\n",
      "Epoch 45/50\n",
      "84/84 [==============================] - 43s 475ms/step - loss: 1.1607 - accuracy: 0.6310 - val_loss: 1.1334 - val_accuracy: 0.6445\n",
      "Epoch 46/50\n",
      "84/84 [==============================] - 42s 469ms/step - loss: 1.1598 - accuracy: 0.6299 - val_loss: 1.1320 - val_accuracy: 0.6429\n",
      "Epoch 47/50\n",
      "84/84 [==============================] - 42s 470ms/step - loss: 1.1599 - accuracy: 0.6315 - val_loss: 1.1423 - val_accuracy: 0.6334\n",
      "Epoch 48/50\n",
      "84/84 [==============================] - 43s 472ms/step - loss: 1.1613 - accuracy: 0.6294 - val_loss: 1.1331 - val_accuracy: 0.6441\n",
      "Epoch 49/50\n",
      "84/84 [==============================] - 234s 3s/step - loss: 1.1572 - accuracy: 0.6312 - val_loss: 1.1301 - val_accuracy: 0.6415\n",
      "Epoch 50/50\n",
      "84/84 [==============================] - 596s 7s/step - loss: 1.1573 - accuracy: 0.6322 - val_loss: 1.1297 - val_accuracy: 0.6424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x20f09080e20>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n================ EXPERIMENT A: No-Encoder =================\")\n",
    "\n",
    "# Build the classifier head that takes raw images\n",
    "clf_Ab = build_classifier3_no_encoder(dense_units=384, dropout=0.3)\n",
    "\n",
    "# Compile (same optimizer/loss/metrics)\n",
    "clf_Ab.compile(\n",
    "    optimizer=optimizers.Adam(LR_FREEZE),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train\n",
    "clf_Ab.fit(\n",
    "    clf_train_ds,\n",
    "    validation_data=clf_val_ds,\n",
    "    epochs=FREEZE_EPOCHS,\n",
    "    verbose=1\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".newvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
